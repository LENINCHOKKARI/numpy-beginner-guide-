{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Project 2: Student Performance Analysis\n",
    "\n",
    "Welcome to your advanced data analysis project! In this notebook, you'll analyze student academic performance using statistical methods and advanced visualizations.\n",
    "\n",
    "## üéØ Project Objectives\n",
    "- Analyze student performance across subjects\n",
    "- Perform statistical significance testing\n",
    "- Identify top performers and at-risk students\n",
    "- Generate educational insights and recommendations\n",
    "- Create comprehensive performance reports\n",
    "\n",
    "## üìã Advanced Skills You'll Practice\n",
    "- Statistical hypothesis testing\n",
    "- Correlation analysis\n",
    "- Performance benchmarking\n",
    "- Educational data mining\n",
    "- Advanced data visualization\n",
    "\n",
    "Let's begin this comprehensive analysis! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"SciPy version: {stats.__version__ if hasattr(stats, '__version__') else 'Available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 1: Load and Prepare Student Data\n",
    "\n",
    "Let's load our student performance dataset and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load student data\n",
    "try:\n",
    "    students = pd.read_csv('../datasets/student_grades.csv')\n",
    "    print(f\"‚úÖ Successfully loaded data for {len(students)} students\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found. Creating sample data for demonstration...\")\n",
    "    # Create comprehensive sample data\n",
    "    np.random.seed(42)\n",
    "    students = pd.DataFrame({\n",
    "        'Student_ID': range(1, 101),\n",
    "        'Name': [f'Student_{i}' for i in range(1, 101)],\n",
    "        'Math': np.random.randint(60, 100, 100),\n",
    "        'Science': np.random.randint(55, 95, 100),\n",
    "        'English': np.random.randint(65, 100, 100),\n",
    "        'Grade_Level': np.random.choice(['9th', '10th', '11th', '12th'], 100),\n",
    "        'Gender': np.random.choice(['Male', 'Female'], 100)\n",
    "    })\n",
    "    print(f\"üìä Created sample dataset with {len(students)} students\")\n",
    "\n",
    "# Define subject columns\n",
    "subjects = ['Math', 'Science', 'English']\n",
    "\n",
    "# Calculate derived metrics\n",
    "students['Total_Score'] = students[subjects].sum(axis=1)\n",
    "students['Average_Score'] = students[subjects].mean(axis=1)\n",
    "\n",
    "# Grade classification function\n",
    "def assign_letter_grade(score):\n",
    "    if score >= 90: return 'A'\n",
    "    elif score >= 80: return 'B'\n",
    "    elif score >= 70: return 'C'\n",
    "    elif score >= 60: return 'D'\n",
    "    else: return 'F'\n",
    "\n",
    "students['Letter_Grade'] = students['Average_Score'].apply(assign_letter_grade)\n",
    "\n",
    "print(\"\\nüìã Dataset Overview:\")\n",
    "print(f\"Shape: {students.shape}\")\n",
    "print(f\"Columns: {list(students.columns)}\")\n",
    "print(\"\\nüîç First 5 students:\")\n",
    "print(students.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality and basic statistics\n",
    "print(\"üîç Data Quality Check:\")\n",
    "print(f\"Missing values:\\n{students.isnull().sum()}\")\n",
    "print(f\"\\nGrade level distribution:\\n{students['Grade_Level'].value_counts()}\")\n",
    "if 'Gender' in students.columns:\n",
    "    print(f\"\\nGender distribution:\\n{students['Gender'].value_counts()}\")\n",
    "\n",
    "print(f\"\\nüìä Performance Overview:\")\n",
    "print(f\"Average score across all subjects: {students['Average_Score'].mean():.2f}\")\n",
    "print(f\"Highest average score: {students['Average_Score'].max():.2f}\")\n",
    "print(f\"Lowest average score: {students['Average_Score'].min():.2f}\")\n",
    "print(f\"Standard deviation: {students['Average_Score'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Step 2: Subject Performance Analysis\n",
    "\n",
    "Let's analyze performance across different subjects and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject analysis\n",
    "print(\"üìö SUBJECT PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "subject_stats = students[subjects].describe().round(2)\n",
    "print(\"Subject Statistics:\")\n",
    "print(subject_stats)\n",
    "\n",
    "# Find best and worst subjects\n",
    "subject_means = students[subjects].mean()\n",
    "best_subject = subject_means.idxmax()\n",
    "worst_subject = subject_means.idxmin()\n",
    "\n",
    "print(f\"\\nüèÜ Best performing subject: {best_subject} (avg: {subject_means[best_subject]:.2f})\")\n",
    "print(f\"üìâ Most challenging subject: {worst_subject} (avg: {subject_means[worst_subject]:.2f})\")\n",
    "print(f\"Performance gap: {subject_means[best_subject] - subject_means[worst_subject]:.2f} points\")\n",
    "\n",
    "# Subject correlations\n",
    "correlations = students[subjects].corr()\n",
    "print(\"\\nüîó Subject Correlations:\")\n",
    "print(correlations.round(3))\n",
    "\n",
    "# Find strongest correlation\n",
    "corr_values = correlations.unstack().drop_duplicates()\n",
    "strongest_corr = corr_values[corr_values < 1.0].max()\n",
    "strongest_pair = corr_values[corr_values == strongest_corr].index[0]\n",
    "print(f\"\\nStrongest correlation: {strongest_pair[0]} & {strongest_pair[1]} (r = {strongest_corr:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject performance visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Subject Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Subject means comparison\n",
    "subject_means.plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Average Scores by Subject')\n",
    "axes[0, 0].set_ylabel('Average Score')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Subject distribution box plots\n",
    "students[subjects].boxplot(ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Score Distribution by Subject')\n",
    "axes[0, 1].set_ylabel('Scores')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Correlation heatmap\n",
    "correlation_matrix = students[subjects + ['Average_Score']].corr()\n",
    "im = axes[1, 0].imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[1, 0].set_xticks(range(len(correlation_matrix.columns)))\n",
    "axes[1, 0].set_yticks(range(len(correlation_matrix.columns)))\n",
    "axes[1, 0].set_xticklabels(correlation_matrix.columns, rotation=45)\n",
    "axes[1, 0].set_yticklabels(correlation_matrix.columns)\n",
    "axes[1, 0].set_title('Subject Correlation Matrix')\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(len(correlation_matrix.columns)):\n",
    "        axes[1, 0].text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}', \n",
    "                       ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "# 4. Subject performance histogram\n",
    "for subject in subjects:\n",
    "    axes[1, 1].hist(students[subject], alpha=0.7, label=subject, bins=15)\n",
    "axes[1, 1].set_title('Score Distribution by Subject')\n",
    "axes[1, 1].set_xlabel('Score')\n",
    "axes[1, 1].set_ylabel('Number of Students')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìö Subject analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Step 3: Grade Level Analysis\n",
    "\n",
    "Let's analyze performance differences across grade levels and test for statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade level analysis\n",
    "print(\"üéì GRADE LEVEL ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "grade_level_stats = students.groupby('Grade_Level').agg({\n",
    "    'Average_Score': ['mean', 'std', 'count'],\n",
    "    'Math': 'mean',\n",
    "    'Science': 'mean',\n",
    "    'English': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Performance by Grade Level:\")\n",
    "print(grade_level_stats)\n",
    "\n",
    "# Statistical significance test (ANOVA)\n",
    "grade_groups = [group['Average_Score'].values for name, group in students.groupby('Grade_Level')]\n",
    "f_stat, p_value = stats.f_oneway(*grade_groups)\n",
    "\n",
    "print(f\"\\nüìä ANOVA Test Results:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant difference between grade levels: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nüîç Post-hoc analysis (pairwise comparisons):\")\n",
    "    grade_levels = students['Grade_Level'].unique()\n",
    "    for i, grade1 in enumerate(grade_levels):\n",
    "        for grade2 in grade_levels[i+1:]:\n",
    "            group1 = students[students['Grade_Level'] == grade1]['Average_Score']\n",
    "            group2 = students[students['Grade_Level'] == grade2]['Average_Score']\n",
    "            t_stat, t_p = stats.ttest_ind(group1, group2)\n",
    "            if t_p < 0.05:\n",
    "                print(f\"   {grade1} vs {grade2}: Significant difference (p = {t_p:.4f})\")\n",
    "\n",
    "# Best and worst performing grade levels\n",
    "grade_means = students.groupby('Grade_Level')['Average_Score'].mean().sort_values(ascending=False)\n",
    "print(f\"\\nüèÜ Grade level rankings:\")\n",
    "for i, (grade, avg) in enumerate(grade_means.items(), 1):\n",
    "    print(f\"{i}. {grade}: {avg:.2f} average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade level visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Grade Level Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Average performance by grade level\n",
    "grade_level_avg = students.groupby('Grade_Level')['Average_Score'].mean().sort_values(ascending=False)\n",
    "axes[0, 0].bar(grade_level_avg.index, grade_level_avg.values, color='lightgreen')\n",
    "axes[0, 0].set_title('Average Performance by Grade Level')\n",
    "axes[0, 0].set_ylabel('Average Score')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(grade_level_avg.values):\n",
    "    axes[0, 0].text(i, v + 1, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Performance distribution by grade level\n",
    "grade_data = [students[students['Grade_Level'] == grade]['Average_Score'].values \n",
    "              for grade in students['Grade_Level'].unique()]\n",
    "axes[0, 1].boxplot(grade_data, labels=students['Grade_Level'].unique())\n",
    "axes[0, 1].set_title('Score Distribution by Grade Level')\n",
    "axes[0, 1].set_ylabel('Average Score')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Subject performance by grade level\n",
    "grade_subject_means = students.groupby('Grade_Level')[subjects].mean()\n",
    "x = np.arange(len(subjects))\n",
    "width = 0.2\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "for i, (grade, scores) in enumerate(grade_subject_means.iterrows()):\n",
    "    axes[1, 0].bar(x + i*width, scores.values, width, label=grade, \n",
    "                   color=colors[i % len(colors)], alpha=0.8)\n",
    "\n",
    "axes[1, 0].set_title('Subject Performance by Grade Level')\n",
    "axes[1, 0].set_xlabel('Subjects')\n",
    "axes[1, 0].set_ylabel('Average Score')\n",
    "axes[1, 0].set_xticks(x + width * 1.5)\n",
    "axes[1, 0].set_xticklabels(subjects)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Grade distribution by grade level\n",
    "grade_distribution = pd.crosstab(students['Grade_Level'], students['Letter_Grade'], normalize='index') * 100\n",
    "grade_distribution.plot(kind='bar', stacked=True, ax=axes[1, 1], \n",
    "                       color=['red', 'orange', 'yellow', 'lightgreen', 'green'])\n",
    "axes[1, 1].set_title('Letter Grade Distribution by Grade Level')\n",
    "axes[1, 1].set_xlabel('Grade Level')\n",
    "axes[1, 1].set_ylabel('Percentage of Students')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].legend(title='Letter Grade', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéì Grade level analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë• Step 4: Gender Analysis (if available)\n",
    "\n",
    "Let's analyze performance differences by gender and test for statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender analysis (if gender data is available)\n",
    "if 'Gender' in students.columns:\n",
    "    print(\"üë• GENDER ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    gender_stats = students.groupby('Gender').agg({\n",
    "        'Average_Score': ['mean', 'std', 'count'],\n",
    "        'Math': 'mean',\n",
    "        'Science': 'mean',\n",
    "        'English': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"Performance by Gender:\")\n",
    "    print(gender_stats)\n",
    "    \n",
    "    # T-test for gender differences\n",
    "    male_scores = students[students['Gender'] == 'Male']['Average_Score']\n",
    "    female_scores = students[students['Gender'] == 'Female']['Average_Score']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(male_scores, female_scores)\n",
    "    \n",
    "    print(f\"\\nüìä T-test Results:\")\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    print(f\"Significant gender difference: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(male_scores) - 1) * male_scores.var() + \n",
    "                         (len(female_scores) - 1) * female_scores.var()) / \n",
    "                        (len(male_scores) + len(female_scores) - 2))\n",
    "    cohens_d = (male_scores.mean() - female_scores.mean()) / pooled_std\n",
    "    \n",
    "    print(f\"Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "    if abs(cohens_d) < 0.2:\n",
    "        effect_size = \"Small\"\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        effect_size = \"Medium\"\n",
    "    else:\n",
    "        effect_size = \"Large\"\n",
    "    print(f\"Effect size interpretation: {effect_size}\")\n",
    "    \n",
    "    # Subject-specific gender analysis\n",
    "    print(f\"\\nüìö Subject-specific gender differences:\")\n",
    "    for subject in subjects:\n",
    "        male_subject = students[students['Gender'] == 'Male'][subject]\n",
    "        female_subject = students[students['Gender'] == 'Female'][subject]\n",
    "        t_stat_subj, p_val_subj = stats.ttest_ind(male_subject, female_subject)\n",
    "        \n",
    "        print(f\"{subject}: Male avg = {male_subject.mean():.2f}, Female avg = {female_subject.mean():.2f}\")\n",
    "        print(f\"   Significant difference: {'Yes' if p_val_subj < 0.05 else 'No'} (p = {p_val_subj:.4f})\")\n",
    "else:\n",
    "    print(\"üë• Gender data not available in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender visualization (if available)\n",
    "if 'Gender' in students.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Gender Performance Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Average performance by gender\n",
    "    gender_avg = students.groupby('Gender')['Average_Score'].mean()\n",
    "    axes[0, 0].bar(gender_avg.index, gender_avg.values, color=['lightblue', 'lightpink'])\n",
    "    axes[0, 0].set_title('Average Performance by Gender')\n",
    "    axes[0, 0].set_ylabel('Average Score')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(gender_avg.values):\n",
    "        axes[0, 0].text(i, v + 1, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. Subject performance by gender\n",
    "    gender_subject_means = students.groupby('Gender')[subjects].mean()\n",
    "    x = np.arange(len(subjects))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0, 1].bar(x - width/2, gender_subject_means.loc['Male'], width, \n",
    "                   label='Male', alpha=0.8, color='lightblue')\n",
    "    axes[0, 1].bar(x + width/2, gender_subject_means.loc['Female'], width, \n",
    "                   label='Female', alpha=0.8, color='lightpink')\n",
    "    axes[0, 1].set_title('Subject Performance by Gender')\n",
    "    axes[0, 1].set_xlabel('Subjects')\n",
    "    axes[0, 1].set_ylabel('Average Score')\n",
    "    axes[0, 1].set_xticks(x)\n",
    "    axes[0, 1].set_xticklabels(subjects)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Score distribution by gender\n",
    "    male_scores = students[students['Gender'] == 'Male']['Average_Score']\n",
    "    female_scores = students[students['Gender'] == 'Female']['Average_Score']\n",
    "    \n",
    "    axes[1, 0].hist(male_scores, alpha=0.7, label='Male', bins=15, color='lightblue')\n",
    "    axes[1, 0].hist(female_scores, alpha=0.7, label='Female', bins=15, color='lightpink')\n",
    "    axes[1, 0].set_title('Score Distribution by Gender')\n",
    "    axes[1, 0].set_xlabel('Average Score')\n",
    "    axes[1, 0].set_ylabel('Number of Students')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 4. Grade distribution by gender\n",
    "    gender_grade_dist = pd.crosstab(students['Gender'], students['Letter_Grade'], normalize='index') * 100\n",
    "    gender_grade_dist.plot(kind='bar', ax=axes[1, 1], \n",
    "                          color=['red', 'orange', 'yellow', 'lightgreen', 'green'])\n",
    "    axes[1, 1].set_title('Letter Grade Distribution by Gender')\n",
    "    axes[1, 1].set_xlabel('Gender')\n",
    "    axes[1, 1].set_ylabel('Percentage of Students')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=0)\n",
    "    axes[1, 1].legend(title='Letter Grade', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üë• Gender analysis completed!\")\n",
    "else:\n",
    "    print(\"Skipping gender visualization - data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Step 5: Identify Top Performers and At-Risk Students\n",
    "\n",
    "Let's identify students who excel and those who need additional support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top performers analysis\n",
    "print(\"üèÜ TOP PERFORMERS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Overall top performers\n",
    "top_students = students.nlargest(10, 'Average_Score')[['Name', 'Average_Score', 'Grade_Level', 'Letter_Grade'] + subjects]\n",
    "print(\"Top 10 Students Overall:\")\n",
    "print(top_students.to_string(index=False))\n",
    "\n",
    "# Top performers by subject\n",
    "print(f\"\\nüìö Top Performers by Subject:\")\n",
    "for subject in subjects:\n",
    "    top_in_subject = students.nlargest(3, subject)[['Name', subject, 'Grade_Level']]\n",
    "    print(f\"\\n{subject} Top 3:\")\n",
    "    for i, (_, student) in enumerate(top_in_subject.iterrows(), 1):\n",
    "        print(f\"  {i}. {student['Name']}: {student[subject]} ({student['Grade_Level']})\")\n",
    "\n",
    "# Excellence analysis\n",
    "excellent_students = students[students['Letter_Grade'] == 'A']\n",
    "print(f\"\\n‚≠ê Excellence Statistics:\")\n",
    "print(f\"Students with A grade: {len(excellent_students)} ({len(excellent_students)/len(students)*100:.1f}%)\")\n",
    "if len(excellent_students) > 0:\n",
    "    print(f\"Average score of A students: {excellent_students['Average_Score'].mean():.2f}\")\n",
    "    print(f\"Grade level distribution of A students:\")\n",
    "    print(excellent_students['Grade_Level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At-risk students analysis\n",
    "print(\"üö® AT-RISK STUDENTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Students with average below 70 (C grade threshold)\n",
    "at_risk = students[students['Average_Score'] < 70][['Name', 'Average_Score', 'Grade_Level'] + subjects]\n",
    "\n",
    "if len(at_risk) > 0:\n",
    "    print(f\"Students needing support: {len(at_risk)} ({len(at_risk)/len(students)*100:.1f}%)\")\n",
    "    print(\"\\nAt-risk students details:\")\n",
    "    print(at_risk.to_string(index=False))\n",
    "    \n",
    "    # Subject-specific support needed\n",
    "    print(f\"\\nüìö Subject-specific support needed:\")\n",
    "    for subject in subjects:\n",
    "        weak_in_subject = students[students[subject] < 70]\n",
    "        if len(weak_in_subject) > 0:\n",
    "            print(f\"{subject}: {len(weak_in_subject)} students ({len(weak_in_subject)/len(students)*100:.1f}%)\")\n",
    "            print(f\"   Average score: {weak_in_subject[subject].mean():.2f}\")\n",
    "            print(f\"   Lowest score: {weak_in_subject[subject].min():.2f}\")\n",
    "        else:\n",
    "            print(f\"{subject}: No students below 70\")\n",
    "    \n",
    "    # Grade level analysis of at-risk students\n",
    "    print(f\"\\nüéì At-risk students by grade level:\")\n",
    "    at_risk_by_grade = at_risk['Grade_Level'].value_counts()\n",
    "    for grade, count in at_risk_by_grade.items():\n",
    "        total_in_grade = len(students[students['Grade_Level'] == grade])\n",
    "        percentage = count / total_in_grade * 100\n",
    "        print(f\"{grade}: {count}/{total_in_grade} students ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"üéâ Great news! No students are currently at risk (all above 70 average).\")\n",
    "\n",
    "# Identify students with high variance (inconsistent performance)\n",
    "students['Score_Variance'] = students[subjects].var(axis=1)\n",
    "inconsistent_students = students.nlargest(5, 'Score_Variance')[['Name', 'Score_Variance'] + subjects + ['Average_Score']]\n",
    "\n",
    "print(f\"\\nüìä Students with inconsistent performance (high variance):\")\n",
    "print(inconsistent_students.to_string(index=False))\n",
    "print(\"\\nNote: These students show large differences between subjects and may benefit from targeted support.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Grade Distribution Analysis\n",
    "\n",
    "Let's analyze the overall grade distribution and performance patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution analysis\n",
    "print(\"üìä GRADE DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "grade_dist = students['Letter_Grade'].value_counts().sort_index()\n",
    "grade_percentages = (grade_dist / len(students) * 100).round(2)\n",
    "\n",
    "print(\"Overall Grade Distribution:\")\n",
    "for grade, count in grade_dist.items():\n",
    "    percentage = grade_percentages[grade]\n",
    "    print(f\"Grade {grade}: {count} students ({percentage}%)\")\n",
    "\n",
    "# Grade distribution by grade level\n",
    "if len(students['Grade_Level'].unique()) > 1:\n",
    "    print(\"\\nüéì Grade Distribution by Grade Level:\")\n",
    "    grade_level_dist = pd.crosstab(students['Grade_Level'], students['Letter_Grade'], normalize='index') * 100\n",
    "    print(grade_level_dist.round(2))\n",
    "\n",
    "# Performance benchmarks\n",
    "print(f\"\\nüìà Performance Benchmarks:\")\n",
    "print(f\"Students meeting/exceeding expectations (C+ or better): {len(students[students['Average_Score'] >= 70])} ({len(students[students['Average_Score'] >= 70])/len(students)*100:.1f}%)\")\n",
    "print(f\"Students exceeding expectations (B+ or better): {len(students[students['Average_Score'] >= 80])} ({len(students[students['Average_Score'] >= 80])/len(students)*100:.1f}%)\")\n",
    "print(f\"Students showing excellence (A grade): {len(students[students['Average_Score'] >= 90])} ({len(students[students['Average_Score'] >= 90])/len(students)*100:.1f}%)\")\n",
    "\n",
    "# Calculate class performance metrics\n",
    "class_average = students['Average_Score'].mean()\n",
    "class_median = students['Average_Score'].median()\n",
    "class_std = students['Average_Score'].std()\n",
    "\n",
    "print(f\"\\nüìä Class Performance Metrics:\")\n",
    "print(f\"Class average: {class_average:.2f}\")\n",
    "print(f\"Class median: {class_median:.2f}\")\n",
    "print(f\"Standard deviation: {class_std:.2f}\")\n",
    "print(f\"Performance consistency: {'High' if class_std < 10 else 'Moderate' if class_std < 15 else 'Low'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive grade distribution visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Comprehensive Grade Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Overall grade distribution\n",
    "grade_dist.plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Overall Grade Distribution')\n",
    "axes[0, 0].set_xlabel('Letter Grade')\n",
    "axes[0, 0].set_ylabel('Number of Students')\n",
    "axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, (grade, count) in enumerate(grade_dist.items()):\n",
    "    percentage = grade_percentages[grade]\n",
    "    axes[0, 0].text(i, count + 0.5, f'{percentage}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Score distribution histogram\n",
    "axes[0, 1].hist(students['Average_Score'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].axvline(class_average, color='red', linestyle='--', label=f'Mean: {class_average:.1f}')\n",
    "axes[0, 1].axvline(class_median, color='blue', linestyle='--', label=f'Median: {class_median:.1f}')\n",
    "axes[0, 1].set_title('Score Distribution')\n",
    "axes[0, 1].set_xlabel('Average Score')\n",
    "axes[0, 1].set_ylabel('Number of Students')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Performance by grade level\n",
    "grade_level_avg = students.groupby('Grade_Level')['Average_Score'].mean().sort_values(ascending=False)\n",
    "axes[0, 2].bar(grade_level_avg.index, grade_level_avg.values, color='orange')\n",
    "axes[0, 2].set_title('Average Performance by Grade Level')\n",
    "axes[0, 2].set_ylabel('Average Score')\n",
    "axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Subject performance comparison\n",
    "subject_means.plot(kind='bar', ax=axes[1, 0], color='lightcoral')\n",
    "axes[1, 0].set_title('Average Performance by Subject')\n",
    "axes[1, 0].set_ylabel('Average Score')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Top vs Bottom performers\n",
    "top_10_pct = students.nlargest(int(len(students) * 0.1), 'Average_Score')['Average_Score'].mean()\n",
    "bottom_10_pct = students.nsmallest(int(len(students) * 0.1), 'Average_Score')['Average_Score'].mean()\n",
    "middle_80_pct = students.iloc[int(len(students) * 0.1):int(len(students) * 0.9)]['Average_Score'].mean()\n",
    "\n",
    "performance_groups = ['Top 10%', 'Middle 80%', 'Bottom 10%']\n",
    "performance_scores = [top_10_pct, middle_80_pct, bottom_10_pct]\n",
    "colors = ['green', 'yellow', 'red']\n",
    "\n",
    "axes[1, 1].bar(performance_groups, performance_scores, color=colors, alpha=0.7)\n",
    "axes[1, 1].set_title('Performance by Student Groups')\n",
    "axes[1, 1].set_ylabel('Average Score')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(performance_scores):\n",
    "    axes[1, 1].text(i, v + 1, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 6. Grade distribution pie chart\n",
    "axes[1, 2].pie(grade_dist.values, labels=grade_dist.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 2].set_title('Grade Distribution (Pie Chart)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Grade distribution analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Step 7: Generate Educational Insights & Recommendations\n",
    "\n",
    "Based on our comprehensive analysis, let's generate actionable educational insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive educational insights\n",
    "print(\"üí° EDUCATIONAL INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Subject-based insights\n",
    "print(\"üìö SUBJECT INSIGHTS:\")\n",
    "print(f\"1. {best_subject} is the strongest subject with an average of {subject_means[best_subject]:.2f}\")\n",
    "print(f\"2. {worst_subject} needs attention with an average of {subject_means[worst_subject]:.2f}\")\n",
    "print(f\"3. Subject performance gap: {subject_means[best_subject] - subject_means[worst_subject]:.2f} points\")\n",
    "\n",
    "# Find the most correlated subjects\n",
    "max_corr = 0\n",
    "corr_subjects = None\n",
    "for i in range(len(subjects)):\n",
    "    for j in range(i+1, len(subjects)):\n",
    "        corr_val = correlations.iloc[i, j]\n",
    "        if corr_val > max_corr:\n",
    "            max_corr = corr_val\n",
    "            corr_subjects = (subjects[i], subjects[j])\n",
    "\n",
    "if corr_subjects:\n",
    "    print(f\"4. {corr_subjects[0]} and {corr_subjects[1]} are highly correlated (r = {max_corr:.3f})\")\n",
    "    print(f\"   ‚Üí Integrated teaching approach recommended\")\n",
    "\n",
    "# Grade level insights\n",
    "print(f\"\\nüéì GRADE LEVEL INSIGHTS:\")\n",
    "best_grade_level = grade_level_avg.index[0]\n",
    "worst_grade_level = grade_level_avg.index[-1]\n",
    "print(f\"1. {best_grade_level} grade shows highest performance ({grade_level_avg[best_grade_level]:.2f} average)\")\n",
    "print(f\"2. {worst_grade_level} grade needs additional support ({grade_level_avg[worst_grade_level]:.2f} average)\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"3. Statistically significant differences exist between grade levels (p = {p_value:.4f})\")\n",
    "    print(f\"   ‚Üí Grade-specific interventions recommended\")\n",
    "else:\n",
    "    print(f\"3. No significant differences between grade levels (p = {p_value:.4f})\")\n",
    "    print(f\"   ‚Üí Consistent teaching standards across grades\")\n",
    "\n",
    "# Performance distribution insights\n",
    "print(f\"\\nüìä PERFORMANCE DISTRIBUTION INSIGHTS:\")\n",
    "excellence_rate = len(students[students['Letter_Grade'] == 'A']) / len(students) * 100\n",
    "proficiency_rate = len(students[students['Average_Score'] >= 70]) / len(students) * 100\n",
    "at_risk_rate = len(students[students['Average_Score'] < 70]) / len(students) * 100\n",
    "\n",
    "print(f\"1. Excellence rate (A grades): {excellence_rate:.1f}%\")\n",
    "print(f\"2. Proficiency rate (70+ average): {proficiency_rate:.1f}%\")\n",
    "print(f\"3. At-risk rate (<70 average): {at_risk_rate:.1f}%\")\n",
    "\n",
    "# Performance consistency\n",
    "if class_std < 10:\n",
    "    consistency = \"High - students perform similarly\"\n",
    "elif class_std < 15:\n",
    "    consistency = \"Moderate - some performance variation\"\n",
    "else:\n",
    "    consistency = \"Low - significant performance gaps exist\"\n",
    "\n",
    "print(f\"4. Class performance consistency: {consistency} (œÉ = {class_std:.2f})\")\n",
    "\n",
    "# Strategic recommendations\n",
    "print(f\"\\nüéØ STRATEGIC RECOMMENDATIONS:\")\n",
    "print(f\"\\nüìà ACADEMIC IMPROVEMENT:\")\n",
    "print(f\"1. Focus remediation efforts on {worst_subject} - consider additional practice sessions\")\n",
    "print(f\"2. Leverage {best_subject} success strategies for other subjects\")\n",
    "print(f\"3. Implement peer tutoring programs pairing strong and struggling students\")\n",
    "\n",
    "if at_risk_rate > 20:\n",
    "    print(f\"4. HIGH PRIORITY: {at_risk_rate:.1f}% of students need immediate intervention\")\n",
    "elif at_risk_rate > 10:\n",
    "    print(f\"4. MODERATE PRIORITY: {at_risk_rate:.1f}% of students need targeted support\")\n",
    "else:\n",
    "    print(f\"4. LOW PRIORITY: Only {at_risk_rate:.1f}% of students need additional support\")\n",
    "\n",
    "print(f\"\\nüë• INDIVIDUALIZED SUPPORT:\")\n",
    "if len(at_risk) > 0:\n",
    "    print(f\"1. Create individualized learning plans for {len(at_risk)} at-risk students\")\n",
    "    print(f\"2. Implement weekly progress monitoring for struggling students\")\n",
    "else:\n",
    "    print(f\"1. Maintain current support systems - no students currently at risk\")\n",
    "\n",
    "print(f\"3. Establish mentorship programs for top performers to help peers\")\n",
    "print(f\"4. Consider advanced placement opportunities for high achievers\")\n",
    "\n",
    "print(f\"\\nüìä MONITORING & ASSESSMENT:\")\n",
    "print(f\"1. Implement monthly progress assessments to track improvement\")\n",
    "print(f\"2. Create subject-specific intervention programs based on correlation analysis\")\n",
    "print(f\"3. Develop early warning systems for identifying at-risk students\")\n",
    "print(f\"4. Regular parent-teacher conferences for students below proficiency\")\n",
    "\n",
    "# Calculate overall educational health score\n",
    "health_score = (\n",
    "    (proficiency_rate / 100 * 40) +  # Proficiency rate weight\n",
    "    (excellence_rate / 100 * 30) +   # Excellence rate weight\n",
    "    ((100 - at_risk_rate) / 100 * 20) +  # Low at-risk rate weight\n",
    "    (min(class_std, 20) / 20 * 10)   # Consistency weight (inverted)\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä OVERALL EDUCATIONAL HEALTH SCORE: {health_score:.1f}/100\")\n",
    "if health_score >= 80:\n",
    "    print(\"üü¢ Excellent educational outcomes - maintain current practices\")\n",
    "elif health_score >= 60:\n",
    "    print(\"üü° Good educational outcomes - focus on identified improvement areas\")\n",
    "else:\n",
    "    print(\"üî¥ Educational outcomes need improvement - implement recommendations urgently\")\n",
    "\n",
    "print(f\"\\nüéâ Analysis complete! Use these insights to improve student outcomes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 8: Executive Education Dashboard\n",
    "\n",
    "Let's create a final comprehensive dashboard for educational stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive educational dashboard\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "fig.suptitle('üìä COMPREHENSIVE STUDENT PERFORMANCE DASHBOARD', fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "# Create a grid layout\n",
    "gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Key metrics (top row)\n",
    "metrics = {\n",
    "    'Total Students': len(students),\n",
    "    'Class Average': f\"{class_average:.1f}\",\n",
    "    'Excellence Rate': f\"{excellence_rate:.1f}%\",\n",
    "    'At-Risk Rate': f\"{at_risk_rate:.1f}%\"\n",
    "}\n",
    "\n",
    "colors = ['lightblue', 'lightgreen', 'gold', 'lightcoral']\n",
    "for i, (metric, value) in enumerate(metrics.items()):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    ax.text(0.5, 0.5, f\"{metric}\\n{value}\", ha='center', va='center', \n",
    "            fontsize=14, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor=colors[i], alpha=0.8))\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Grade distribution (second row, left)\n",
    "ax1 = fig.add_subplot(gs[1, :2])\n",
    "grade_dist.plot(kind='bar', ax=ax1, color='skyblue')\n",
    "ax1.set_title('Grade Distribution', fontweight='bold', fontsize=12)\n",
    "ax1.set_xlabel('Letter Grade')\n",
    "ax1.set_ylabel('Number of Students')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Subject performance (second row, right)\n",
    "ax2 = fig.add_subplot(gs[1, 2:])\n",
    "subject_means.plot(kind='bar', ax=ax2, color='lightgreen')\n",
    "ax2.set_title('Subject Performance', fontweight='bold', fontsize=12)\n",
    "ax2.set_ylabel('Average Score')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Score distribution (third row, left)\n",
    "ax3 = fig.add_subplot(gs[2, :2])\n",
    "ax3.hist(students['Average_Score'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "ax3.axvline(class_average, color='red', linestyle='--', linewidth=2, label=f'Mean: {class_average:.1f}')\n",
    "ax3.set_title('Score Distribution', fontweight='bold', fontsize=12)\n",
    "ax3.set_xlabel('Average Score')\n",
    "ax3.set_ylabel('Number of Students')\n",
    "ax3.legend()\n",
    "\n",
    "# Performance by grade level (third row, right)\n",
    "ax4 = fig.add_subplot(gs[2, 2:])\n",
    "grade_level_avg.plot(kind='bar', ax=ax4, color='lightcoral')\n",
    "ax4.set_title('Performance by Grade Level', fontweight='bold', fontsize=12)\n",
    "ax4.set_ylabel('Average Score')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Subject correlation heatmap (fourth row, left)\n",
    "ax5 = fig.add_subplot(gs[3, :2])\n",
    "correlation_matrix = students[subjects].corr()\n",
    "im = ax5.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "ax5.set_xticks(range(len(subjects)))\n",
    "ax5.set_yticks(range(len(subjects)))\n",
    "ax5.set_xticklabels(subjects)\n",
    "ax5.set_yticklabels(subjects)\n",
    "ax5.set_title('Subject Correlations', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(len(subjects)):\n",
    "    for j in range(len(subjects)):\n",
    "        ax5.text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}', \n",
    "                ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "# Performance groups comparison (fourth row, right)\n",
    "ax6 = fig.add_subplot(gs[3, 2:])\n",
    "performance_groups = ['Top 10%', 'Middle 80%', 'Bottom 10%']\n",
    "performance_scores = [top_10_pct, middle_80_pct, bottom_10_pct]\n",
    "colors_perf = ['green', 'yellow', 'red']\n",
    "\n",
    "bars = ax6.bar(performance_groups, performance_scores, color=colors_perf, alpha=0.7)\n",
    "ax6.set_title('Performance by Student Groups', fontweight='bold', fontsize=12)\n",
    "ax6.set_ylabel('Average Score')\n",
    "\n",
    "# Add value labels\n",
    "for bar, score in zip(bars, performance_scores):\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            f'{score:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Executive education dashboard created successfully!\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ STUDENT PERFORMANCE ANALYSIS PROJECT COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úÖ What you accomplished:\")\n",
    "print(\"   ‚Ä¢ Comprehensive statistical analysis of student performance\")\n",
    "print(\"   ‚Ä¢ Subject-wise performance evaluation\")\n",
    "print(\"   ‚Ä¢ Grade level and demographic analysis\")\n",
    "print(\"   ‚Ä¢ Statistical significance testing (ANOVA, t-tests)\")\n",
    "print(\"   ‚Ä¢ Identification of top performers and at-risk students\")\n",
    "print(\"   ‚Ä¢ Correlation analysis between subjects\")\n",
    "print(\"   ‚Ä¢ Educational insights and recommendations\")\n",
    "print(\"   ‚Ä¢ Executive dashboard for stakeholders\")\n",
    "print(\"\\nüöÄ Advanced skills mastered:\")\n",
    "print(\"   ‚Ä¢ Hypothesis testing and statistical inference\")\n",
    "print(\"   ‚Ä¢ Educational data mining techniques\")\n",
    "print(\"   ‚Ä¢ Performance benchmarking and analysis\")\n",
    "print(\"   ‚Ä¢ Advanced data visualization\")\n",
    "print(\"   ‚Ä¢ Business intelligence for education\")\n",
    "print(\"\\nüéØ Next challenges:\")\n",
    "print(\"   ‚Ä¢ Try analyzing your own datasets\")\n",
    "print(\"   ‚Ä¢ Explore machine learning for predictive analytics\")\n",
    "print(\"   ‚Ä¢ Build interactive dashboards with Plotly\")\n",
    "print(\"   ‚Ä¢ Create automated reporting systems\")\n",
    "print(\"\\nCongratulations! You're now ready for advanced data science projects! üéì‚ú®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}